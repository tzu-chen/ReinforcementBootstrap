{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T05:05:10.938489Z",
     "start_time": "2021-10-21T05:05:10.935205Z"
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from scipy.special import hyp2f1\n",
    "from numpy.random import rand\n",
    "from numpy.linalg import norm\n",
    "from numpy import array\n",
    "from numpy import zeros, zeros_like\n",
    "from numpy import ones, ones_like\n",
    "from numpy import inf\n",
    "from numpy import minimum, maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T03:44:28.892852Z",
     "start_time": "2021-10-21T03:44:28.889029Z"
    }
   },
   "outputs": [],
   "source": [
    "def g(h,hb,z,zb):\n",
    "    return (1/2 if h==hb else 1)*(z**h*zb**hb*hyp2f1(h,h,2*h,z)*hyp2f1(hb,hb,2*hb,zb)+zb**h*z**hb*hyp2f1(h,h,2*h,zb)*hyp2f1(hb,hb,2*hb,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T03:44:29.455653Z",
     "start_time": "2021-10-21T03:44:29.452877Z"
    }
   },
   "outputs": [],
   "source": [
    "def p(h,hb,c,z,zb):\n",
    "    return c*(((z-1)*(zb-1))**(1/8)*g(h,hb,z,zb)-z**(1/8)*zb**(1/8)*g(h,hb,1-z,1-zb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T03:44:29.958362Z",
     "start_time": "2021-10-21T03:44:29.956530Z"
    }
   },
   "outputs": [],
   "source": [
    "pts = rand(29,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T03:44:30.444133Z",
     "start_time": "2021-10-21T03:44:30.440538Z"
    }
   },
   "outputs": [],
   "source": [
    "def e(spec,pts):\n",
    "    return [(sum([p(n[0],n[1],n[2],z[0],z[1]) for n in spec]) + ((z[0]-1)*(z[1]-1))**(1/8)-z[0]**(1/8)*z[1]**(1/8)) for z in pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T03:44:30.947865Z",
     "start_time": "2021-10-21T03:44:30.945022Z"
    }
   },
   "outputs": [],
   "source": [
    "test_spec = array([[2.,2.,2.44e-4],[.5,.5,.25],[2.,0.,.016],[4.,0.,2.2e-4],[6.,0.,1.36e-5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T03:44:34.229201Z",
     "start_time": "2021-10-21T03:44:34.226918Z"
    }
   },
   "outputs": [],
   "source": [
    "spins = array([0,0,2,4,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:14:16.421793Z",
     "start_time": "2021-10-21T07:14:16.414659Z"
    }
   },
   "outputs": [],
   "source": [
    "class IsingEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.action_space = gym.spaces.Box(array([-1 for i in range(10)]), array([1 for i in range(10)]))\n",
    "        self.observation_space = gym.spaces.Box(array([-inf for i in range(29)]),array([inf for i in range(29)]))\n",
    "        self.n = 5\n",
    "    def step(self, action, old_reward):\n",
    "        self.state += action\n",
    "        self.state = maximum(zeros_like(self.state), self.state)\n",
    "        self.state = minimum(6.5*ones_like(self.state), self.state)\n",
    "        obs = self._get_obs()\n",
    "        reward = -norm(obs)\n",
    "        if reward > old_reward:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        info = {}\n",
    "        return obs, reward, done, info\n",
    "    def reset(self):\n",
    "        self.state = rand(10)\n",
    "        return self._get_obs()\n",
    "    def _get_obs(self):\n",
    "        spec = [[(self.state[2*i]+spins[i])/2, (self.state[2*i]-spins[i])/2, self.state[2*i+1]]for i in range(self.n)]\n",
    "        return e(spec, pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:10:00.948733Z",
     "start_time": "2021-10-21T07:10:00.939269Z"
    }
   },
   "outputs": [],
   "source": [
    "class IsingEnv2(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.action_space = gym.spaces.Dict({\"index\":gym.spaces.Discrete(10), \"magnitude\":gym.spaces.Box(low=array([-1]),high=array([1]))})\n",
    "        self.observation_space = gym.spaces.Box(array([-inf for i in range(29)]),array([inf for i in range(29)]))\n",
    "        self.n = 5\n",
    "    def step(self, action, old_reward):\n",
    "        self.state[action[\"index\"]] += action[\"magnitude\"]\n",
    "        self.state[action[\"index\"]] = maximum(0, self.state[action[\"index\"]])\n",
    "        self.state[action[\"index\"]] = minimum(6.5, self.state[action[\"index\"]])\n",
    "        obs = self._get_obs()\n",
    "        reward = -norm(obs)\n",
    "        if reward > old_reward:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        info = {}\n",
    "        return obs, reward, done, info\n",
    "    def reset(self):\n",
    "        self.state = rand(10)\n",
    "        return self._get_obs()\n",
    "    def _get_obs(self):\n",
    "        spec = [[(self.state[2*i]+spins[i])/2, (self.state[2*i]-spins[i])/2, self.state[2*i+1]]for i in range(self.n)]\n",
    "        return e(spec, pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:10:01.324648Z",
     "start_time": "2021-10-21T07:10:01.321578Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tzuchen/PycharmProjects/ReinforcementBootstrap/venv/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "ising = IsingEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:14:20.250392Z",
     "start_time": "2021-10-21T07:14:20.243054Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:14:20.447484Z",
     "start_time": "2021-10-21T07:14:20.442584Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class NormalizedActions(gym.ActionWrapper):\n",
    "    def action(self, action):\n",
    "        low  = self.action_space.low\n",
    "        high = self.action_space.high\n",
    "        \n",
    "        action = low + (action + 1.0) * 0.5 * (high - low)\n",
    "        action = np.clip(action, low, high)\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def _reverse_action(self, action):\n",
    "        low  = self.action_space.low\n",
    "        high = self.action_space.high\n",
    "        \n",
    "        action = 2 * (action - low) / (high - low) - 1\n",
    "        action = np.clip(action, low, high)\n",
    "        \n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:14:20.630156Z",
     "start_time": "2021-10-21T07:14:20.624187Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        state, action, reward, next_state, done = map(np.stack, zip(*batch))\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:14:20.804304Z",
     "start_time": "2021-10-21T07:14:20.786264Z"
    }
   },
   "outputs": [],
   "source": [
    "class ValueNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, hidden_dim, init_w=3e-3):\n",
    "        super(ValueNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(state_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.linear3 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class SoftQNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3):\n",
    "        super(SoftQNetwork, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs + num_actions, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.linear3.weight.data.uniform_(-init_w, init_w)\n",
    "        self.linear3.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat([state, action], 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions, hidden_size, init_w=3e-3, log_std_min=-20, log_std_max=2):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        \n",
    "        self.log_std_min = log_std_min\n",
    "        self.log_std_max = log_std_max\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_inputs, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.mean_linear = nn.Linear(hidden_size, num_actions)\n",
    "        self.mean_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.mean_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "        self.log_std_linear = nn.Linear(hidden_size, num_actions)\n",
    "        self.log_std_linear.weight.data.uniform_(-init_w, init_w)\n",
    "        self.log_std_linear.bias.data.uniform_(-init_w, init_w)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.linear1(state))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        \n",
    "        mean    = self.mean_linear(x)\n",
    "        log_std = self.log_std_linear(x)\n",
    "        log_std = torch.clamp(log_std, self.log_std_min, self.log_std_max)\n",
    "        \n",
    "        return mean, log_std\n",
    "    \n",
    "    def evaluate(self, state, epsilon=1e-6):\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = Normal(0, 1)\n",
    "        z      = normal.sample()\n",
    "        action = torch.tanh(mean+ std*z.to(device))\n",
    "        log_prob = Normal(mean, std).log_prob(mean+ std*z.to(device)) - torch.log(1 - action.pow(2) + epsilon)\n",
    "        return action, log_prob, z, mean, log_std\n",
    "        \n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = Normal(0, 1)\n",
    "        z      = normal.sample().to(device)\n",
    "        action = torch.tanh(mean + std*z)\n",
    "        action  = action.cpu()#.detach().cpu().numpy()\n",
    "        return action[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:14:21.077844Z",
     "start_time": "2021-10-21T07:14:21.068362Z"
    }
   },
   "outputs": [],
   "source": [
    "def update(batch_size,gamma=0.99,soft_tau=1e-3,):\n",
    "    \n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    state      = torch.FloatTensor(state).to(device)\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    action     = torch.FloatTensor(action).to(device)\n",
    "    reward     = torch.FloatTensor(reward).unsqueeze(1).to(device)\n",
    "    done       = torch.FloatTensor(np.float32(done)).unsqueeze(1).to(device)\n",
    "\n",
    "    predicted_q_value1 = soft_q_net1(state, action)\n",
    "    predicted_q_value2 = soft_q_net2(state, action)\n",
    "    predicted_value    = value_net(state)\n",
    "    new_action, log_prob, epsilon, mean, log_std = policy_net.evaluate(state)\n",
    "\n",
    "    \n",
    "    \n",
    "# Training Q Function\n",
    "    target_value = target_value_net(next_state)\n",
    "    target_q_value = reward + (1 - done) * gamma * target_value\n",
    "    q_value_loss1 = soft_q_criterion1(predicted_q_value1, target_q_value.detach())\n",
    "    q_value_loss2 = soft_q_criterion2(predicted_q_value2, target_q_value.detach())\n",
    "\n",
    "\n",
    "    soft_q_optimizer1.zero_grad()\n",
    "    q_value_loss1.backward()\n",
    "    soft_q_optimizer1.step()\n",
    "    soft_q_optimizer2.zero_grad()\n",
    "    q_value_loss2.backward()\n",
    "    soft_q_optimizer2.step()    \n",
    "# Training Value Function\n",
    "    predicted_new_q_value = torch.min(soft_q_net1(state, new_action),soft_q_net2(state, new_action))\n",
    "    target_value_func = predicted_new_q_value - log_prob\n",
    "    value_loss = value_criterion(predicted_value, target_value_func.detach())\n",
    "\n",
    "    \n",
    "    value_optimizer.zero_grad()\n",
    "    value_loss.backward()\n",
    "    value_optimizer.step()\n",
    "# Training Policy Function\n",
    "    policy_loss = (log_prob - predicted_new_q_value).mean()\n",
    "\n",
    "    policy_optimizer.zero_grad()\n",
    "    policy_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "    \n",
    "    \n",
    "    for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "        target_param.data.copy_(\n",
    "            target_param.data * (1.0 - soft_tau) + param.data * soft_tau\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:14:21.445465Z",
     "start_time": "2021-10-21T07:14:21.430292Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tzuchen/PycharmProjects/ReinforcementBootstrap/venv/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = IsingEnv()\n",
    "\n",
    "action_dim = env.action_space.shape[0]\n",
    "state_dim  = env.observation_space.shape[0]\n",
    "hidden_dim = 256\n",
    "\n",
    "value_net        = ValueNetwork(state_dim, hidden_dim).to(device)\n",
    "target_value_net = ValueNetwork(state_dim, hidden_dim).to(device)\n",
    "\n",
    "soft_q_net1 = SoftQNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "soft_q_net2 = SoftQNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim).to(device)\n",
    "\n",
    "for target_param, param in zip(target_value_net.parameters(), value_net.parameters()):\n",
    "    target_param.data.copy_(param.data)\n",
    "    \n",
    "\n",
    "value_criterion  = nn.MSELoss()\n",
    "soft_q_criterion1 = nn.MSELoss()\n",
    "soft_q_criterion2 = nn.MSELoss()\n",
    "\n",
    "value_lr  = 5e-4\n",
    "soft_q_lr = 5e-4\n",
    "policy_lr = 5e-4\n",
    "\n",
    "value_optimizer  = optim.Adam(value_net.parameters(), lr=value_lr)\n",
    "soft_q_optimizer1 = optim.Adam(soft_q_net1.parameters(), lr=soft_q_lr)\n",
    "soft_q_optimizer2 = optim.Adam(soft_q_net2.parameters(), lr=soft_q_lr)\n",
    "policy_optimizer = optim.Adam(policy_net.parameters(), lr=policy_lr)\n",
    "\n",
    "replay_buffer_size = 100000\n",
    "replay_buffer = ReplayBuffer(replay_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:14:21.816498Z",
     "start_time": "2021-10-21T07:14:21.813465Z"
    }
   },
   "outputs": [],
   "source": [
    "max_frames  = 4000\n",
    "max_steps   = 500\n",
    "frame_idx   = 0\n",
    "rewards     = []\n",
    "batch_size  = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-21T07:14:22.858Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tzuchen/PycharmProjects/ReinforcementBootstrap/venv/lib64/python3.9/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([64, 10])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "max_reward = -inf\n",
    "while frame_idx < max_frames:\n",
    "    state = env.reset()\n",
    "    episode_reward = 0\n",
    "    for step in range(max_steps):\n",
    "        if frame_idx >1000:\n",
    "            action = policy_net.get_action(state).detach()\n",
    "            next_state, reward, done, _ = env.step(action.numpy(), max_reward)\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "            next_state, reward, done, _ = env.step(action, max_reward)\n",
    "        \n",
    "        \n",
    "        replay_buffer.push(state, action, reward, next_state, done)\n",
    "        \n",
    "        state = next_state\n",
    "        episode_reward += reward\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if len(replay_buffer) > batch_size:\n",
    "            update(batch_size)\n",
    "        if done:\n",
    "            max_reward = reward\n",
    "            break\n",
    "    rewards.append(episode_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:03:03.527393Z",
     "start_time": "2021-10-21T07:03:03.524841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.09155483550659"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:03:07.215573Z",
     "start_time": "2021-10-21T07:03:07.107613Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f14967ee3d0>]"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:03:10.029531Z",
     "start_time": "2021-10-21T07:03:10.026699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 6.5, 0. , 6.5, 6.5, 6.5, 0. , 0. , 6.5, 0. ])"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T07:03:13.039269Z",
     "start_time": "2021-10-21T07:03:13.028059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-976.6383027000994"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-norm(env._get_obs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
